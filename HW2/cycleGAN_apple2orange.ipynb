{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import glob\n",
        "import itertools\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 128\n",
        "NUM_RESIDUAL_BLOCKS = 6\n",
        "BATCH_SIZE = 1\n",
        "LR = 0.0002\n",
        "BETA1 = 0.5\n",
        "LAMBDA_CYCLE = 10.0\n",
        "LAMBDA_IDENTITY = 0.5 * LAMBDA_CYCLE\n",
        "NUM_EPOCHS = 20\n",
        "DECAY_EPOCH = 100\n",
        "CHECKPOINT_INTERVAL = 5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        conv_block = [nn.ReflectionPad2d(1),\n",
        "                      nn.Conv2d(in_features, in_features, 3),\n",
        "                      nn.InstanceNorm2d(in_features),\n",
        "                      nn.ReLU(inplace=True),\n",
        "                      nn.ReflectionPad2d(1),\n",
        "                      nn.Conv2d(in_features, in_features, 3),\n",
        "                      nn.InstanceNorm2d(in_features)]\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class ImageBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if np.random.uniform(0, 1) > 0.5:\n",
        "                    i = np.random.randint(0, self.max_size)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.cat(to_return)"
      ],
      "metadata": {
        "id": "PA__MX-_a51X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, num_residual_blocks=6):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial Convolutional Layers\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(input_nc, 64, 7),\n",
        "                 nn.InstanceNorm2d(64),\n",
        "                 nn.ReLU(inplace=True)]\n",
        "\n",
        "        # Downsampling Layers (3 convolutions)\n",
        "        in_features = 64\n",
        "        out_features = in_features * 2\n",
        "        for _ in range(2):\n",
        "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                      nn.InstanceNorm2d(out_features),\n",
        "                      nn.ReLU(inplace=True)]\n",
        "            in_features = out_features\n",
        "            out_features = in_features * 2\n",
        "\n",
        "        # Residual Blocks (6 blocks for 128x128 images)\n",
        "        for _ in range(num_residual_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling Layers (2 fractionally-strided convolutions with stride 1/2)\n",
        "        out_features = in_features // 2\n",
        "        for _ in range(2):\n",
        "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                      nn.InstanceNorm2d(out_features),\n",
        "                      nn.ReLU(inplace=True)]\n",
        "            in_features = out_features\n",
        "            out_features = in_features // 2\n",
        "\n",
        "        # Output Layer (1 convolution that maps features to RGB)\n",
        "        model += [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(64, output_nc, 7),\n",
        "                  nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super().__init__()\n",
        "\n",
        "        # A: C64-C128-C256-C512\n",
        "        # PatchGAN uses LeakyReLU and no InstanceNorm on the first layer\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(input_nc, 64, normalize=False), # C64 (No Norm)\n",
        "            *discriminator_block(64, 128),                       # C128\n",
        "            *discriminator_block(128, 256),                      # C256\n",
        "            *discriminator_block(256, 512),                      # C512 (Stride 1 on last layer)\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)                      # Output (Maps to 1 channel)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The output size for a 128x128 input will be 14x14.\n",
        "        # For a 256x256 input, the output size is 30x30.\n",
        "        # The PatchGAN concept is achieved by the output shape.\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "qlSjvr0za8ZB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# =======================================================\n",
        "# الف. Loss Functions (LSGAN Loss)\n",
        "# =======================================================\n",
        "\n",
        "class LSGANLoss(nn.Module):\n",
        "    \"\"\"Least Squares GAN Loss\"\"\"\n",
        "    def __init__(self, target_real_label=1.0, target_fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "    def get_target_tensor(self, prediction, target_is_real):\n",
        "        if target_is_real:\n",
        "            target_tensor = self.real_label\n",
        "        else:\n",
        "            target_tensor = self.fake_label\n",
        "        return target_tensor.expand_as(prediction)\n",
        "\n",
        "    def __call__(self, prediction, target_is_real):\n",
        "        target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
        "        return self.loss(prediction, target_tensor)\n",
        "\n",
        "class L1CycleLoss(nn.Module):\n",
        "    \"\"\"L1 Loss for Cycle Consistency and Identity Loss\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss = nn.L1Loss()\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        return self.loss(input, target)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class UnpairedDataset(Dataset):\n",
        "    def __init__(self, root, dataset_name, transform=None):\n",
        "\n",
        "        self.root_path = root\n",
        "        self.dataset_name = dataset_name\n",
        "        self.transform = transform\n",
        "\n",
        "        path_A = os.path.join(self.root_path, self.dataset_name, 'trainA')\n",
        "        path_B = os.path.join(self.root_path, self.dataset_name, 'trainB')\n",
        "\n",
        "        file_search_patterns = ['*.jpg', '*.jpeg', '*.png', '*', '*.webp']\n",
        "\n",
        "        self.files_A = []\n",
        "        self.files_B = []\n",
        "\n",
        "        for pattern in file_search_patterns:\n",
        "            self.files_A.extend(glob.glob(os.path.join(path_A, pattern)))\n",
        "        self.files_A = sorted(list(set(self.files_A)))\n",
        "\n",
        "        for pattern in file_search_patterns:\n",
        "            self.files_B.extend(glob.glob(os.path.join(path_B, pattern)))\n",
        "        self.files_B = sorted(list(set(self.files_B)))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        from PIL import Image\n",
        "\n",
        "        if not self.files_A or not self.files_B:\n",
        "            raise IndexError(\"Dataset lists are empty. Check file paths.\")\n",
        "\n",
        "        index_B = index % len(self.files_B)\n",
        "\n",
        "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]).convert('RGB'))\n",
        "        item_B = self.transform(Image.open(self.files_B[index_B]).convert('RGB'))\n",
        "\n",
        "        return {'A': item_A, 'B': item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        if not self.files_A and not self.files_B:\n",
        "            print(f\"Error: No files found in {os.path.join(self.root_path, self.dataset_name)}/trainA or trainB.\")\n",
        "            return 0\n",
        "        return max(len(self.files_A), len(self.files_B))\n",
        "\n",
        "\n",
        "\n",
        "class UnpairedTestDataset(Dataset):\n",
        "    def __init__(self, root, dataset_name, transform=None):\n",
        "        self.transform = transform\n",
        "        path_A = os.path.join(root, dataset_name, 'testA')\n",
        "        path_B = os.path.join(root, dataset_name, 'testB')\n",
        "\n",
        "        file_search_patterns = ['*.jpg', '*.jpeg', '*.png', '*', '*.webp']\n",
        "\n",
        "        self.files_A = []\n",
        "        for pattern in file_search_patterns:\n",
        "            self.files_A.extend(glob.glob(os.path.join(path_A, pattern)))\n",
        "        self.files_A = sorted(list(set(self.files_A)))\n",
        "\n",
        "        self.files_B = []\n",
        "        for pattern in file_search_patterns:\n",
        "            self.files_B.extend(glob.glob(os.path.join(path_B, pattern)))\n",
        "        self.files_B = sorted(list(set(self.files_B)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        from PIL import Image\n",
        "        index_B = index % len(self.files_B)\n",
        "\n",
        "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]).convert('RGB'))\n",
        "        item_B = self.transform(Image.open(self.files_B[index_B]).convert('RGB'))\n",
        "        return {'A': item_A, 'B': item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ],
      "metadata": {
        "id": "dCCsdF-Da9Dk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(epoch, netG_A2B, netG_B2A, netD_A, netD_B, loss_history, checkpoint_dir='checkpoints_apple'):\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'netG_A2B_state_dict': netG_A2B.state_dict(),\n",
        "        'netG_B2A_state_dict': netG_B2A.state_dict(),\n",
        "        'netD_A_state_dict': netD_A.state_dict(),\n",
        "        'netD_B_state_dict': netD_B.state_dict(),\n",
        "        'loss_history': loss_history\n",
        "    }\n",
        "    filename = os.path.join(checkpoint_dir, f'cyclegan_checkpoint_epoch_{epoch}.pth')\n",
        "    torch.save(state, filename)\n",
        "    print(f\"\\n---> Checkpoint saved successfully at: {filename}\")\n",
        "\n",
        "\n",
        "def train_cyclegan(netG_A2B, netG_B2A, netD_A, netD_B, dataloader):\n",
        "\n",
        "    optimizer_G = optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=LR, betas=(BETA1, 0.999))\n",
        "    optimizer_D_A = optim.Adam(netD_A.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
        "    optimizer_D_B = optim.Adam(netD_B.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
        "\n",
        "    criterion_GAN = LSGANLoss().to(DEVICE)\n",
        "    criterion_cycle = L1CycleLoss().to(DEVICE)\n",
        "    criterion_identity = L1CycleLoss().to(DEVICE) # L1 Loss for identity\n",
        "\n",
        "    fake_A_buffer = ImageBuffer()\n",
        "    fake_B_buffer = ImageBuffer()\n",
        "    n_total_batches = len(dataloader)\n",
        "\n",
        "    def lr_lambda(epoch):\n",
        "        return 1.0 if epoch < DECAY_EPOCH else 1.0 - (epoch - DECAY_EPOCH) / (NUM_EPOCHS - DECAY_EPOCH)\n",
        "\n",
        "    scheduler_G = optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lr_lambda)\n",
        "    scheduler_D_A = optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lr_lambda)\n",
        "    scheduler_D_B = optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lr_lambda)\n",
        "\n",
        "    loss_history = {\n",
        "        'G_total': [],\n",
        "        'D_A': [],\n",
        "        'D_B': [],\n",
        "        'Cycle': [],\n",
        "        'G_A2B_GAN': [],\n",
        "        'G_B2A_GAN': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        for i, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\")):\n",
        "            real_A = batch['A'].to(DEVICE)\n",
        "            real_B = batch['B'].to(DEVICE)\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            loss_identity_A = criterion_identity(netG_B2A(real_A), real_A)\n",
        "            loss_identity_B = criterion_identity(netG_A2B(real_B), real_B)\n",
        "            loss_identity = (loss_identity_A + loss_identity_B) * LAMBDA_IDENTITY\n",
        "\n",
        "            fake_B = netG_A2B(real_A)\n",
        "            loss_GAN_A2B = criterion_GAN(netD_B(fake_B), True) # G_A2B minimizes Ex[(D(G(x)) - 1)^2]\n",
        "\n",
        "            fake_A = netG_B2A(real_B)\n",
        "            loss_GAN_B2A = criterion_GAN(netD_A(fake_A), True) # G_B2A minimizes Ey[(D(F(y)) - 1)^2]\n",
        "            loss_GAN = loss_GAN_A2B + loss_GAN_B2A\n",
        "\n",
        "            # Cycle Loss\n",
        "            reconstructed_A = netG_B2A(fake_B)\n",
        "            loss_cycle_ABA = criterion_cycle(reconstructed_A, real_A)\n",
        "\n",
        "            reconstructed_B = netG_A2B(fake_A)\n",
        "            loss_cycle_BAB = criterion_cycle(reconstructed_B, real_B)\n",
        "            loss_cycle = (loss_cycle_ABA + loss_cycle_BAB) * LAMBDA_CYCLE\n",
        "\n",
        "            # Total Generator Loss\n",
        "            loss_G = loss_GAN + loss_cycle + loss_identity\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "\n",
        "            # D_A Loss (D_A minimizes E_y[(D(y)-1)^2] + E_x[D(G(x))^2])\n",
        "            optimizer_D_A.zero_grad()\n",
        "\n",
        "            # Real Loss\n",
        "            loss_D_real_A = criterion_GAN(netD_A(real_A), True)\n",
        "\n",
        "            # Fake Loss (Use Buffer)\n",
        "            fake_A_pop = fake_A_buffer.push_and_pop(fake_A.detach())\n",
        "            loss_D_fake_A = criterion_GAN(netD_A(fake_A_pop), False)\n",
        "\n",
        "            loss_D_A = (loss_D_real_A + loss_D_fake_A) * 0.5\n",
        "            loss_D_A.backward()\n",
        "            optimizer_D_A.step()\n",
        "\n",
        "            # D_B Loss\n",
        "            optimizer_D_B.zero_grad()\n",
        "\n",
        "            # Real Loss\n",
        "            loss_D_real_B = criterion_GAN(netD_B(real_B), True)\n",
        "\n",
        "            # Fake Loss (Use Buffer)\n",
        "            fake_B_pop = fake_B_buffer.push_and_pop(fake_B.detach())\n",
        "            loss_D_fake_B = criterion_GAN(netD_B(fake_B_pop), False)\n",
        "\n",
        "            loss_D_B = (loss_D_real_B + loss_D_fake_B) * 0.5\n",
        "            loss_D_B.backward()\n",
        "            optimizer_D_B.step()\n",
        "\n",
        "        scheduler_G.step()\n",
        "        scheduler_D_A.step()\n",
        "        scheduler_D_B.step()\n",
        "\n",
        "        loss_history['G_total'].append(loss_G.item())\n",
        "        loss_history['D_A'].append(loss_D_A.item())\n",
        "        loss_history['D_B'].append(loss_D_B.item())\n",
        "        loss_history['Cycle'].append(loss_cycle.item())\n",
        "        loss_history['G_A2B_GAN'].append(loss_GAN_A2B.item())\n",
        "        loss_history['G_B2A_GAN'].append(loss_GAN_B2A.item())\n",
        "\n",
        "        # 9. Checkpointing\n",
        "        if epoch % CHECKPOINT_INTERVAL == 0:\n",
        "            save_checkpoint(epoch, netG_A2B, netG_B2A, netD_A, netD_B, loss_history)"
      ],
      "metadata": {
        "id": "2oMGgAy0bAIK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(int(IMAGE_SIZE * 1.12), Image.Resampling.BICUBIC),\n",
        "    transforms.RandomCrop(IMAGE_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    netG_A2B = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
        "    netG_B2A = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
        "    netD_A = Discriminator(3).to(DEVICE)\n",
        "    netD_B = Discriminator(3).to(DEVICE)\n",
        "\n",
        "\n",
        "    ROOT_PATH = '/content/drive/MyDrive'\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        UnpairedDataset(ROOT_PATH, 'apple2orange', transform),\n",
        "        batch_size=BATCH_SIZE, shuffle=True, pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"--- Starting CycleGAN Training on {DEVICE} ---\")\n",
        "    print(f\"Hyperparameters: LR={LR}, Lambda_Cycle={LAMBDA_CYCLE}, ImageSize={IMAGE_SIZE}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_cyclegan(netG_A2B, netG_B2A, netD_A, netD_B, dataloader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"Training finished. Total time: {end_time - start_time:.2f} seconds.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGQ6pZdLbDV9",
        "outputId": "57852d09-5a87-4034-df93-a0b0341c00e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting CycleGAN Training on cuda ---\n",
            "Hyperparameters: LR=0.0002, Lambda_Cycle=10.0, ImageSize=128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 1019/1019 [13:30<00:00,  1.26it/s]\n",
            "Epoch 2/20: 100%|██████████| 1019/1019 [02:06<00:00,  8.08it/s]\n",
            "Epoch 3/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.10it/s]\n",
            "Epoch 4/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.09it/s]\n",
            "Epoch 5/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---> Checkpoint saved successfully at: checkpoints_apple/cyclegan_checkpoint_epoch_5.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.11it/s]\n",
            "Epoch 7/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.11it/s]\n",
            "Epoch 8/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.10it/s]\n",
            "Epoch 9/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.09it/s]\n",
            "Epoch 10/20: 100%|██████████| 1019/1019 [02:06<00:00,  8.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---> Checkpoint saved successfully at: checkpoints_apple/cyclegan_checkpoint_epoch_10.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 1019/1019 [02:06<00:00,  8.09it/s]\n",
            "Epoch 12/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.09it/s]\n",
            "Epoch 13/20: 100%|██████████| 1019/1019 [02:06<00:00,  8.08it/s]\n",
            "Epoch 14/20: 100%|██████████| 1019/1019 [02:06<00:00,  8.08it/s]\n",
            "Epoch 15/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---> Checkpoint saved successfully at: checkpoints_apple/cyclegan_checkpoint_epoch_15.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.09it/s]\n",
            "Epoch 17/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.10it/s]\n",
            "Epoch 18/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.09it/s]\n",
            "Epoch 19/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.10it/s]\n",
            "Epoch 20/20: 100%|██████████| 1019/1019 [02:05<00:00,  8.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---> Checkpoint saved successfully at: checkpoints_apple/cyclegan_checkpoint_epoch_20.pth\n",
            "Training finished. Total time: 3204.18 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def load_checkpoint(filename, netG_A2B, netG_B2A, netD_A, netD_B):\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"Loading checkpoint from: {filename}\")\n",
        "        checkpoint = torch.load(filename, map_location='cpu')\n",
        "\n",
        "        netG_A2B.load_state_dict(checkpoint['netG_A2B_state_dict'])\n",
        "        netG_B2A.load_state_dict(checkpoint['netG_B2A_state_dict'])\n",
        "        netD_A.load_state_dict(checkpoint['netD_A_state_dict'])\n",
        "        netD_B.load_state_dict(checkpoint['netD_B_state_dict'])\n",
        "\n",
        "        return checkpoint['loss_history']\n",
        "    else:\n",
        "        print(f\"Error: Checkpoint file not found: {filename}\")\n",
        "        return None\n",
        "\n",
        "def plot_loss_history(loss_history, num_epochs):\n",
        "    epochs = range(1, num_epochs + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    axes[0].plot(epochs, loss_history['G_total'][:num_epochs], label='Total Generator Loss')\n",
        "    axes[0].plot(epochs, loss_history['Cycle'][:num_epochs], label='Cycle Consistency Loss')\n",
        "    axes[0].set_title('Generator Losses (Total & Cycle)')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    axes[1].plot(epochs, loss_history['G_A2B_GAN'][:num_epochs], label='G_A2B GAN Loss (A to B)')\n",
        "    axes[1].plot(epochs, loss_history['G_B2A_GAN'][:num_epochs], label='G_B2A GAN Loss (B to A)')\n",
        "    axes[1].set_title('Separate Generator GAN Losses')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    axes[2].plot(epochs, loss_history['D_A'][:num_epochs], label='Discriminator A Loss (A domain)')\n",
        "    axes[2].plot(epochs, loss_history['D_B'][:num_epochs], label='Discriminator B Loss (B domain)')\n",
        "    axes[2].set_title('Discriminator Losses')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('Loss')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('cyclegan_loss_plot_modified.png')\n",
        "    plt.close()\n",
        "    print(\"Loss plot saved as 'cyclegan_loss_plot_modified.png'\")\n",
        "\n",
        "def generate_and_plot_samples(netG_A2B, netG_B2A, test_dataloader, epoch, filename):\n",
        "    netG_A2B.eval()\n",
        "    netG_B2A.eval()\n",
        "\n",
        "    data = next(iter(test_dataloader))\n",
        "    real_A = data['A'].to(DEVICE)\n",
        "    real_B = data['B'].to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_B = netG_A2B(real_A)\n",
        "        cycle_A = netG_B2A(fake_B)\n",
        "\n",
        "        fake_A = netG_B2A(real_B)\n",
        "        cycle_B = netG_A2B(fake_A)\n",
        "\n",
        "    def to_img_np(tensor):\n",
        "        # Denormalize: [-1, 1] -> [0, 1]\n",
        "        img = (tensor.data.cpu().squeeze().permute(1, 2, 0) + 1) / 2.0\n",
        "        return np.clip(img.numpy(), 0, 1)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n",
        "    fig.suptitle(f\"CycleGAN Results - Epoch {epoch}\", fontsize=16)\n",
        "\n",
        "    axes[0, 0].imshow(to_img_np(real_A))\n",
        "    axes[0, 0].set_title('Real A (Apple)')\n",
        "    axes[0, 1].imshow(to_img_np(fake_B))\n",
        "    axes[0, 1].set_title('Fake B (Orange)')\n",
        "    axes[0, 2].imshow(to_img_np(cycle_A))\n",
        "    axes[0, 2].set_title('Cycle A (Reconstructed)')\n",
        "\n",
        "    axes[1, 0].imshow(to_img_np(real_B))\n",
        "    axes[1, 0].set_title('Real B (Orange)')\n",
        "    axes[1, 1].imshow(to_img_np(fake_A))\n",
        "    axes[1, 1].set_title('Fake A (Apple)')\n",
        "    axes[1, 2].imshow(to_img_np(cycle_B))\n",
        "    axes[1, 2].set_title('Cycle B (Reconstructed)')\n",
        "\n",
        "    for ax in axes.flat:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\"Sample images saved as '{filename}'\")"
      ],
      "metadata": {
        "id": "axpR40m1bF7H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    netG_A2B = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
        "    netG_B2A = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
        "    netD_A = Discriminator(3).to(DEVICE)\n",
        "    netD_B = Discriminator(3).to(DEVICE)\n",
        "\n",
        "    ROOT_PATH = '/content/drive/MyDrive'\n",
        "    test_dataset = UnpairedTestDataset(ROOT_PATH, 'apple2orange', transform)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    epochs_to_plot = [5, 10, 20]\n",
        "    full_loss_history = None\n",
        "\n",
        "    for epoch in epochs_to_plot:\n",
        "        checkpoint_file = f'/content/checkpoints_apple/cyclegan_checkpoint_epoch_{epoch}.pth'\n",
        "\n",
        "        loss_history = load_checkpoint(checkpoint_file, netG_A2B, netG_B2A, netD_A, netD_B)\n",
        "\n",
        "        if loss_history is not None:\n",
        "            if epoch == 20:\n",
        "                full_loss_history = loss_history\n",
        "\n",
        "            generate_and_plot_samples(\n",
        "                netG_A2B, netG_B2A, test_dataloader, epoch,\n",
        "                filename=f'cyclegan_samples_epoch_{epoch}.png'\n",
        "            )\n",
        "\n",
        "    if full_loss_history is not None:\n",
        "        plot_loss_history(full_loss_history, num_epochs=20)\n",
        "    else:\n",
        "        print(\"\\nCould not find Epoch 20 checkpoint to plot the full loss history.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ9cEmHMbJEQ",
        "outputId": "17a36c55-4c15-4000-d513-4fcde827ab38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint from: /content/checkpoints_apple/cyclegan_checkpoint_epoch_5.pth\n",
            "Sample images saved as 'cyclegan_samples_epoch_5.png'\n",
            "Loading checkpoint from: /content/checkpoints_apple/cyclegan_checkpoint_epoch_10.pth\n",
            "Sample images saved as 'cyclegan_samples_epoch_10.png'\n",
            "Loading checkpoint from: /content/checkpoints_apple/cyclegan_checkpoint_epoch_20.pth\n",
            "Sample images saved as 'cyclegan_samples_epoch_20.png'\n",
            "Loss plot saved as 'cyclegan_loss_plot_modified.png'\n"
          ]
        }
      ]
    }
  ]
}