{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "NUM_RESIDUAL_BLOCKS = 6\n",
    "BATCH_SIZE = 1\n",
    "LR = 0.0002\n",
    "BETA1 = 0.5\n",
    "LAMBDA_CYCLE = 10.0\n",
    "NUM_EPOCHS = 20\n",
    "DECAY_EPOCH = 100\n",
    "CHECKPOINT_INTERVAL = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        conv_block = [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features)]\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_residual_blocks=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial Convolutional Layers\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, 64, 7),\n",
    "                 nn.InstanceNorm2d(64),\n",
    "                 nn.ReLU(inplace=True)]\n",
    "\n",
    "        # Downsampling Layers (3 convolutions)\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual Blocks (6 blocks for 128x128 images)\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling Layers (2 fractionally-strided convolutions with stride 1/2)\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output Layer (1 convolution that maps features to RGB)\n",
    "        model += [nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(64, output_nc, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# =======================================================\n",
    "# Discriminator (70x70 PatchGAN)\n",
    "# =======================================================\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super().__init__()\n",
    "\n",
    "        # A: C64-C128-C256-C512\n",
    "        # PatchGAN uses LeakyReLU and no InstanceNorm on the first layer\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(input_nc, 64, normalize=False), # C64 (No Norm)\n",
    "            *discriminator_block(64, 128),                       # C128\n",
    "            *discriminator_block(128, 256),                      # C256\n",
    "            *discriminator_block(256, 512),                      # C512 (Stride 1 on last layer)\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)                      # Output (Maps to 1 channel)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The output size for a 128x128 input will be 14x14.\n",
    "        # For a 256x256 input, the output size is 30x30.\n",
    "        # The PatchGAN concept is achieved by the output shape.\n",
    "        return self.model(x)\n",
    "        import numpy as np\n",
    "# =======================================================\n",
    "# Loss Functions (LSGAN Loss)\n",
    "# =======================================================\n",
    "\n",
    "class LSGANLoss(nn.Module):\n",
    "    \"\"\"Least Squares GAN Loss\"\"\"\n",
    "    def __init__(self, target_real_label=1.0, target_fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "        return self.loss(prediction, target_tensor)\n",
    "\n",
    "class L1CycleLoss(nn.Module):\n",
    "    \"\"\"L1 Loss for Cycle Consistency and Identity Loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = nn.L1Loss()\n",
    "\n",
    "    def __call__(self, input, target):\n",
    "        return self.loss(input, target)\n",
    "\n",
    "# =======================================================\n",
    "# Dataset (Apple2Orange)\n",
    "# =======================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class UnpairedDataset(Dataset):\n",
    "    def __init__(self, root, dataset_name, transform=None):\n",
    "\n",
    "        self.root_path = root\n",
    "        self.dataset_name = dataset_name\n",
    "        self.transform = transform\n",
    "\n",
    "        path_A = os.path.join(self.root_path, self.dataset_name, 'trainA')\n",
    "        path_B = os.path.join(self.root_path, self.dataset_name, 'trainB')\n",
    "\n",
    "        file_search_patterns = ['*.jpg', '*.jpeg', '*.png', '*', '*.webp']\n",
    "\n",
    "        self.files_A = []\n",
    "        self.files_B = []\n",
    "\n",
    "        for pattern in file_search_patterns:\n",
    "            self.files_A.extend(glob.glob(os.path.join(path_A, pattern)))\n",
    "        self.files_A = sorted(list(set(self.files_A)))\n",
    "\n",
    "        for pattern in file_search_patterns:\n",
    "            self.files_B.extend(glob.glob(os.path.join(path_B, pattern)))\n",
    "        self.files_B = sorted(list(set(self.files_B)))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        from PIL import Image\n",
    "\n",
    "        if not self.files_A or not self.files_B:\n",
    "            raise IndexError(\"Dataset lists are empty. Check file paths.\")\n",
    "\n",
    "        index_B = index % len(self.files_B)\n",
    "\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]).convert('RGB'))\n",
    "        item_B = self.transform(Image.open(self.files_B[index_B]).convert('RGB'))\n",
    "\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.files_A and not self.files_B:\n",
    "            print(f\"Error: No files found in {os.path.join(self.root_path, self.dataset_name)}/trainA or trainB.\")\n",
    "            return 0\n",
    "        return max(len(self.files_A), len(self.files_B))\n",
    "\n",
    "\n",
    "\n",
    "class UnpairedTestDataset(Dataset):\n",
    "    def __init__(self, root, dataset_name, transform=None):\n",
    "        self.transform = transform\n",
    "        path_A = os.path.join(root, dataset_name, 'testA')\n",
    "        path_B = os.path.join(root, dataset_name, 'testB')\n",
    "\n",
    "        file_search_patterns = ['*.jpg', '*.jpeg', '*.png', '*', '*.webp']\n",
    "\n",
    "        self.files_A = []\n",
    "        for pattern in file_search_patterns:\n",
    "            self.files_A.extend(glob.glob(os.path.join(path_A, pattern)))\n",
    "        self.files_A = sorted(list(set(self.files_A)))\n",
    "\n",
    "        self.files_B = []\n",
    "        for pattern in file_search_patterns:\n",
    "            self.files_B.extend(glob.glob(os.path.join(path_B, pattern)))\n",
    "        self.files_B = sorted(list(set(self.files_B)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        from PIL import Image\n",
    "        index_B = index % len(self.files_B)\n",
    "\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]).convert('RGB'))\n",
    "        item_B = self.transform(Image.open(self.files_B[index_B]).convert('RGB'))\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))\n",
    "\n",
    "def save_checkpoint(epoch, netG_A2B, netG_B2A, netD_A, netD_B, loss_history, checkpoint_dir='checkpoints'):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    state = {\n",
    "     'epoch': epoch,\n",
    "     'netG_A2B_state_dict': netG_A2B.state_dict(),\n",
    "     'netG_B2A_state_dict': netG_B2A.state_dict(),\n",
    "     'netD_A_state_dict': netD_A.state_dict(),\n",
    "     'netD_B_state_dict': netD_B.state_dict(),\n",
    "     'loss_history': loss_history\n",
    "    }\n",
    "    filename = os.path.join(checkpoint_dir, f'cyclegan_checkpoint_epoch_{epoch}.pth')\n",
    "    torch.save(state, filename)\n",
    "    print(f\"\\n---> Checkpoint saved successfully at: {filename}\")\n",
    "\n",
    "\n",
    "def train_cyclegan(netG_A2B, netG_B2A, netD_A, netD_B, dataloader):\n",
    "    \n",
    "    optimizer_G = optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=LR, betas=(BETA1, 0.999))\n",
    "    optimizer_D_A = optim.Adam(netD_A.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
    "    optimizer_D_B = optim.Adam(netD_B.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
    "\n",
    "    criterion_GAN = LSGANLoss().to(DEVICE)\n",
    "    criterion_cycle = L1CycleLoss().to(DEVICE)\n",
    "\n",
    "    def lr_lambda(epoch):\n",
    "        return 1.0 if epoch < DECAY_EPOCH else 1.0 - (epoch - DECAY_EPOCH) / (NUM_EPOCHS - DECAY_EPOCH)\n",
    "\n",
    "    scheduler_G = optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lr_lambda)\n",
    "    scheduler_D_A = optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lr_lambda)\n",
    "    scheduler_D_B = optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lr_lambda)\n",
    "\n",
    "    loss_history = {\n",
    "        'G_total': [], \n",
    "        'D_A': [], \n",
    "        'D_B': [], \n",
    "        'Cycle': [], \n",
    "        'G_A2B_GAN': [], \n",
    "        'G_B2A_GAN': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        for i, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\")):\n",
    "            real_A = batch['A'].to(DEVICE)\n",
    "            real_B = batch['B'].to(DEVICE)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "\n",
    "            fake_B = netG_A2B(real_A)\n",
    "            loss_GAN_A2B = criterion_GAN(netD_B(fake_B), True) # G_A2B minimizes Ex[(D(G(x)) - 1)^2]\n",
    "\n",
    "            fake_A = netG_B2A(real_B)\n",
    "            loss_GAN_B2A = criterion_GAN(netD_A(fake_A), True) # G_B2A minimizes Ey[(D(F(y)) - 1)^2]\n",
    "            loss_GAN = loss_GAN_A2B + loss_GAN_B2A\n",
    "\n",
    "            # Cycle Loss\n",
    "            reconstructed_A = netG_B2A(fake_B)\n",
    "            loss_cycle_ABA = criterion_cycle(reconstructed_A, real_A)\n",
    "\n",
    "            reconstructed_B = netG_A2B(fake_A)\n",
    "            loss_cycle_BAB = criterion_cycle(reconstructed_B, real_B)\n",
    "            loss_cycle = (loss_cycle_ABA + loss_cycle_BAB) * LAMBDA_CYCLE\n",
    "\n",
    "            # Total Generator Loss (Only GAN + Cycle)\n",
    "            loss_G = loss_GAN + loss_cycle\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "\n",
    "            # D_A Loss\n",
    "            optimizer_D_A.zero_grad()\n",
    "\n",
    "            # Real Loss\n",
    "            loss_D_real_A = criterion_GAN(netD_A(real_A), True)\n",
    "\n",
    "            loss_D_fake_A = criterion_GAN(netD_A(fake_A.detach()), False)\n",
    "\n",
    "            loss_D_A = (loss_D_real_A + loss_D_fake_A) * 0.5\n",
    "            loss_D_A.backward()\n",
    "            optimizer_D_A.step()\n",
    "\n",
    "            # D_B Loss\n",
    "            optimizer_D_B.zero_grad()\n",
    "\n",
    "            # Real Loss\n",
    "            loss_D_real_B = criterion_GAN(netD_B(real_B), True)\n",
    "\n",
    "            # Fake Loss (Using latest fake_B, no buffer)\n",
    "            loss_D_fake_B = criterion_GAN(netD_B(fake_B.detach()), False)\n",
    "\n",
    "            loss_D_B = (loss_D_real_B + loss_D_fake_B) * 0.5\n",
    "            loss_D_B.backward()\n",
    "            optimizer_D_B.step()\n",
    "\n",
    "        scheduler_G.step()\n",
    "        scheduler_D_A.step()\n",
    "        scheduler_D_B.step()\n",
    "\n",
    "        loss_history['G_total'].append(loss_G.item())\n",
    "        loss_history['D_A'].append(loss_D_A.item())\n",
    "        loss_history['D_B'].append(loss_D_B.item())\n",
    "        loss_history['Cycle'].append(loss_cycle.item())\n",
    "        loss_history['G_A2B_GAN'].append(loss_GAN_A2B.item())\n",
    "        loss_history['G_B2A_GAN'].append(loss_GAN_B2A.item())\n",
    "        \n",
    "        # 9. Checkpointing\n",
    "        if epoch % CHECKPOINT_INTERVAL == 0:\n",
    "            save_checkpoint(epoch, netG_A2B, netG_B2A, netD_A, netD_B, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting CycleGAN Training on cuda ---\n",
      "Hyperparameters: LR=0.0002, Lambda_Cycle=10.0, ImageSize=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 1334/1334 [02:07<00:00, 10.44it/s]\n",
      "Epoch 2/20: 100%|██████████| 1334/1334 [02:02<00:00, 10.90it/s]\n",
      "Epoch 3/20: 100%|██████████| 1334/1334 [02:07<00:00, 10.46it/s]\n",
      "Epoch 4/20: 100%|██████████| 1334/1334 [02:24<00:00,  9.25it/s]\n",
      "Epoch 5/20: 100%|██████████| 1334/1334 [02:05<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Checkpoint saved successfully at: checkpoints\\cyclegan_checkpoint_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 1334/1334 [02:04<00:00, 10.74it/s]\n",
      "Epoch 7/20: 100%|██████████| 1334/1334 [02:04<00:00, 10.72it/s]\n",
      "Epoch 8/20: 100%|██████████| 1334/1334 [02:04<00:00, 10.73it/s]\n",
      "Epoch 9/20: 100%|██████████| 1334/1334 [02:04<00:00, 10.75it/s]\n",
      "Epoch 10/20: 100%|██████████| 1334/1334 [02:04<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Checkpoint saved successfully at: checkpoints\\cyclegan_checkpoint_epoch_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 1334/1334 [02:04<00:00, 10.70it/s]\n",
      "Epoch 12/20: 100%|██████████| 1334/1334 [02:02<00:00, 10.89it/s]\n",
      "Epoch 13/20: 100%|██████████| 1334/1334 [02:05<00:00, 10.65it/s]\n",
      "Epoch 14/20: 100%|██████████| 1334/1334 [02:21<00:00,  9.45it/s]\n",
      "Epoch 15/20: 100%|██████████| 1334/1334 [02:18<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Checkpoint saved successfully at: checkpoints\\cyclegan_checkpoint_epoch_15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 1334/1334 [02:23<00:00,  9.28it/s]\n",
      "Epoch 17/20: 100%|██████████| 1334/1334 [02:10<00:00, 10.19it/s]\n",
      "Epoch 18/20: 100%|██████████| 1334/1334 [02:19<00:00,  9.57it/s]\n",
      "Epoch 19/20: 100%|██████████| 1334/1334 [02:13<00:00, 10.01it/s]\n",
      "Epoch 20/20: 100%|██████████| 1334/1334 [02:18<00:00,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Checkpoint saved successfully at: checkpoints\\cyclegan_checkpoint_epoch_20.pth\n",
      "Training finished. Total time: 2607.12 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(int(IMAGE_SIZE * 1.12), Image.Resampling.BICUBIC),\n",
    "    transforms.RandomCrop(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    netG_A2B = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
    "    netG_B2A = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
    "    netD_A = Discriminator(3).to(DEVICE)\n",
    "    netD_B = Discriminator(3).to(DEVICE)\n",
    "\n",
    "    ROOT_PATH = './'\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        UnpairedDataset(ROOT_PATH, 'horse2zebra', transform),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"--- Starting CycleGAN Training on {DEVICE} ---\")\n",
    "    print(f\"Hyperparameters: LR={LR}, Lambda_Cycle={LAMBDA_CYCLE}, ImageSize={IMAGE_SIZE}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_cyclegan(netG_A2B, netG_B2A, netD_A, netD_B, dataloader)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Training finished. Total time: {end_time - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint(filename, netG_A2B, netG_B2A, netD_A, netD_B):\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Loading checkpoint from: {filename}\")\n",
    "        checkpoint = torch.load(filename, map_location='cpu')\n",
    "\n",
    "        netG_A2B.load_state_dict(checkpoint['netG_A2B_state_dict'])\n",
    "        netG_B2A.load_state_dict(checkpoint['netG_B2A_state_dict'])\n",
    "        netD_A.load_state_dict(checkpoint['netD_A_state_dict'])\n",
    "        netD_B.load_state_dict(checkpoint['netD_B_state_dict'])\n",
    "\n",
    "        return checkpoint['loss_history']\n",
    "    else:\n",
    "        print(f\"Error: Checkpoint file not found: {filename}\")\n",
    "        return None\n",
    "\n",
    "def plot_loss_history(loss_history, num_epochs):\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    axes[0].plot(epochs, loss_history['G_total'][:num_epochs], label='Total Generator Loss')\n",
    "    axes[0].plot(epochs, loss_history['Cycle'][:num_epochs], label='Cycle Consistency Loss')\n",
    "    axes[0].set_title('Generator Losses (Total & Cycle)')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    axes[1].plot(epochs, loss_history['G_A2B_GAN'][:num_epochs], label='G_A2B GAN Loss (A to B)')\n",
    "    axes[1].plot(epochs, loss_history['G_B2A_GAN'][:num_epochs], label='G_B2A GAN Loss (B to A)')\n",
    "    axes[1].set_title('Separate Generator GAN Losses')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    axes[2].plot(epochs, loss_history['D_A'][:num_epochs], label='Discriminator A Loss (A domain)')\n",
    "    axes[2].plot(epochs, loss_history['D_B'][:num_epochs], label='Discriminator B Loss (B domain)')\n",
    "    axes[2].set_title('Discriminator Losses')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Loss')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cyclegan_loss_plot_modified.png')\n",
    "    plt.close()\n",
    "    print(\"Loss plot saved as 'cyclegan_loss_plot_modified.png'\")\n",
    "\n",
    "\n",
    "def generate_and_plot_samples(netG_A2B, netG_B2A, test_dataloader, epoch, filename):\n",
    "    netG_A2B.eval()\n",
    "    netG_B2A.eval()\n",
    "\n",
    "    data = next(iter(test_dataloader))\n",
    "    real_A = data['A'].to(DEVICE)\n",
    "    real_B = data['B'].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        cycle_A = netG_B2A(fake_B)\n",
    "\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        cycle_B = netG_A2B(fake_A)\n",
    "\n",
    "    def to_img_np(tensor):\n",
    "        img = (tensor.data.cpu().squeeze().permute(1, 2, 0) + 1) / 2.0\n",
    "        return np.clip(img.numpy(), 0, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n",
    "    fig.suptitle(f\"CycleGAN Results - Epoch {epoch}\", fontsize=16)\n",
    "\n",
    "    axes[0, 0].imshow(to_img_np(real_A))\n",
    "    axes[0, 0].set_title('Real A (horse)')\n",
    "    axes[0, 1].imshow(to_img_np(fake_B))\n",
    "    axes[0, 1].set_title('Fake B (zebra)')\n",
    "    axes[0, 2].imshow(to_img_np(cycle_A))\n",
    "    axes[0, 2].set_title('Cycle A (Reconstructed)')\n",
    "    \n",
    "    axes[1, 0].imshow(to_img_np(real_B))\n",
    "    axes[1, 0].set_title('Real B (zebra)')\n",
    "    axes[1, 1].imshow(to_img_np(fake_A))\n",
    "    axes[1, 1].set_title('Fake A (horse)')\n",
    "    axes[1, 2].imshow(to_img_np(cycle_B))\n",
    "    axes[1, 2].set_title('Cycle B (Reconstructed)')\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    print(f\"Sample images saved as '{filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: ./checkpoints/cyclegan_checkpoint_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_5608\\3778742420.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location='cpu') # بارگذاری روی CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample images saved as 'cyclegan_samples_epoch_5.png'\n",
      "Loading checkpoint from: ./checkpoints/cyclegan_checkpoint_epoch_10.pth\n",
      "Sample images saved as 'cyclegan_samples_epoch_10.png'\n",
      "Loading checkpoint from: ./checkpoints/cyclegan_checkpoint_epoch_20.pth\n",
      "Sample images saved as 'cyclegan_samples_epoch_20.png'\n",
      "Loss plot saved as 'cyclegan_loss_plot_modified.png'\n"
     ]
    }
   ],
   "source": [
    "netG_A2B = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
    "netG_B2A = Generator(3, 3, NUM_RESIDUAL_BLOCKS).to(DEVICE)\n",
    "netD_A = Discriminator(3).to(DEVICE)\n",
    "netD_B = Discriminator(3).to(DEVICE)\n",
    "\n",
    "ROOT_PATH = '.'\n",
    "test_dataset = UnpairedTestDataset(ROOT_PATH, 'horse2zebra', transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "epochs_to_plot = [5, 10, 20]\n",
    "full_loss_history = None\n",
    "for epoch in epochs_to_plot:\n",
    "    checkpoint_file = f'./checkpoints/cyclegan_checkpoint_epoch_{epoch}.pth'\n",
    "\n",
    "    loss_history = load_checkpoint(checkpoint_file, netG_A2B, netG_B2A, netD_A, netD_B)\n",
    "    if loss_history is not None:\n",
    "\n",
    "        if epoch == 20:\n",
    "            full_loss_history = loss_history\n",
    "        generate_and_plot_samples(\n",
    "            netG_A2B, netG_B2A, test_dataloader, epoch,\n",
    "            filename=f'cyclegan_samples_epoch_{epoch}.png'\n",
    "        )\n",
    "if full_loss_history is not None:\n",
    "    plot_loss_history(full_loss_history, num_epochs=20)\n",
    "else:\n",
    "    print(\"\\nCould not find Epoch 20 checkpoint to plot the full loss history.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
